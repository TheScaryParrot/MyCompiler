\chapter{Auswertung}
Abschliessend will ich den QHScompiler, wie in Abschnitt \ref{cha:2-Vergleich} beschrieben, mit zwei weiteren Compilern vergleichen.
Diese werden in Geschwindigkeit der Kompilierung, Geschwindigkeit des Output-Codes, Benutzerfreundlichkeit und Offenheit für Erweiterung bewertet. 

\section{Geschwindigkeit der Kompilierung} \label{sec:compare-compilespeed}
Für die Messung der Kompilierungsdauer wird eine Funktion, die prüft, ob eine Zahl eine Primzahl ist, kompiliert. Diese Funktion wurde so geschrieben, dass jedes Feature, das alle drei Compiler unterstützen, verwendet wird.
Dazu gehören Variablen, Funktionen und Expressions sowie If-Else-Statements und Loops. Die Funktion wurde in die jeweiligen Sprachen übersetzt und mehrmals in das Programm eingefügt. Anschliessend wurde jedes Programm zehnmal kompiliert.
Die durchschnittliche Dauer der Kompilierung ist in \ref{fig:compilespeed} ersichtlich.

\begin{figure}[h!]
\centering
\label{fig:compilespeed}
\begin{tikzpicture}
    \begin{axis}[
        enlargelimits=false,
        xlabel=Anzahl der Funktionen,
        xmode=log,
        log basis x=10,
        ylabel=Kompilierungsdauer (ms),
        ymode=log,
        log basis y=10,
        %tick style={draw=none},
        tick label style={font=\bfseries\large},
        grid=major,
        legend pos=north west,
    ]
    \addplot[
        smooth,
        color=blue,
        mark=square,
        mark size=2pt]
    table [col sep=comma]
    {resources/data/compilespeed_qhs.csv};
    \addlegendentry{QHS}
    \addplot[
        smooth,
        color=red,
        mark=square,
        mark size=2pt]
    table [col sep=comma]
    {resources/data/compilespeed_ths.csv};
    \addlegendentry{THS}
    \addplot[
        smooth,
        color=green,
        mark=square,
        mark size=2pt]
    table [col sep=comma]
    {resources/data/compilespeed_c.csv};
    \addlegendentry{GCC}
    \end{axis}
\end{tikzpicture}
\caption{Vergleich der Kompilierungsdauer mit Log-Log Skalen}
\end{figure}

Interessant ist hierbei, dass sowohl QHS als auch GCC mit einer hohen Kompilierungsdauer beginnen und sich später linear verhalten.
Zu Beginn glänzt THS zwar mit einer sehr schnellen Kompilierung, steigt daraufhin jedoch exponentiell an.
Bei etwas mehr als 10³ Kopien der Funktion wird GCC und daraufhin zwischen 10⁴ und 10⁵ Kopien auch der QHScompiler schneller als der THScompiler.
Für die exponentielle Kompilerungsdauer des THScompilers habe ich leider keine Erklärung. Grundsätzlich sollten alle Schritte, die der THScompiler durchläuft, eine lineare Komplexität aufweisen.
%Daher liegt der Fehler wahrscheinlich bei meinen eigenen C++ Kenntnissen.
Der Unterschied zwischen den Kompilierungsdauern von GCC und dem QHScompiler erscheint durch die logarithmischen Skalen konstant.
Tatsächlich braucht der QHScompiler aber ab einer Programmgrösse über 10² Funktionskopien konsistent 7-8 mal länger als GCC. 
Der QHScompiler ist somit deutlich geschlagen. Wie GCC zeigt, liegt das Problem der exponentiellen Kompilierungsdauer des THScompilers nicht am Aufbau des traditionellen Compilers und viel mehr an meiner Implementation davon.
Daher würde ich in dieser Kategorie des Vergleichs den Sieg für den traditionellen Compiler aussprechen.


\section{Geschwindigkeit des Output-Codes} \label{sec:execute_speed}
Die Geschwindigkeit eines kompilierten Programmes wird anhand eines Algorithmus zur Berechnung von Primzahlen gemessen. Sowie bei der Funktion aus Abschnitt \ref{sec:compare-compilespeed} ist dieser Algorithmus so geschrieben,
dass er möglichst jedes von allen drei Compilern unterstütze Feature verwendet. Der Algorithmus wurde von Hand in die jeweiligen Sprachen übersetzt und daraufhin für verschiedene Mengen an zu berechnenden Primzahlen je zehnmal ausgeführt.

\begin{figure}[H]
    \centering
    \label{fig:executespeed_optimized}
    \begin{tikzpicture}
        \begin{axis}[
            enlargelimits=false,
            xlabel=Menge der Primzahlen,
            ylabel=Ausführungsdauer (ms),
            %tick style={draw=none},
            tick label style={font=\bfseries\large},
            grid=major,
            legend pos=north west,
        ]
        \addplot[
            smooth,
            color=blue,
            mark=square,
            mark size=2pt]
        table [col sep=comma]
        {resources/data/executespeed_qhs.csv};
        \addlegendentry{QHS}
        \addplot[
            smooth,
            color=red,
            mark=square,
            mark size=2pt]
        table [col sep=comma]
        {resources/data/executespeed_ths.csv};
        \addlegendentry{THS}
        \addplot[
            smooth,
            color=green,
            mark=square,
            mark size=2pt]
        table [col sep=comma]
        {resources/data/executespeed_optimized_c.csv};
        \addlegendentry{GCC}
        \end{axis}
    \end{tikzpicture}
    \caption{Vergleich der Ausführungsdauer mit GCC Optimierung}
\end{figure}

Wie in Abbildung \ref{fig:executespeed_optimized} ersichtlich, beginnen alle drei kompilierten Programme mit einer sehr tiefen Ausführungsdauer.
Die Progamme des THS- und QHScompilers werden bis zum Schluss nahezu gleich schnell ausgeführt.
Das von GCC generierte Programm ist jedoch deutlich schneller als die Programme des THS- und QHScompilers.
Dies liegt ganz klar an den Optimierungsmethoden von GCC. Wenn man die Optimierung beim Kompilieren mit GCC deaktiviert, sieht die Grafik wie folgt aus:

\begin{figure}[H]
    \centering
    \label{fig:executespeed}
    \begin{tikzpicture}
        \begin{axis}[
            enlargelimits=false,
            xlabel=Menge der Primzahlen,
            ylabel=Ausführungsdauer (ms),
            %tick style={draw=none},
            tick label style={font=\bfseries\large},
            grid=major,
            legend pos=north west,
        ]
        \addplot[
            smooth,
            color=blue,
            mark=square,
            mark size=2pt]
        table [col sep=comma]
        {resources/data/executespeed_qhs.csv};
        \addlegendentry{QHS}
        \addplot[
            smooth,
            color=red,
            mark=square,
            mark size=2pt]
        table [col sep=comma]
        {resources/data/executespeed_ths.csv};
        \addlegendentry{THS}
        \addplot[
            smooth,
            color=green,
            mark=square,
            mark size=2pt]
        table [col sep=comma]
        {resources/data/executespeed_c.csv};
        \addlegendentry{GCC}
        \end{axis}
    \end{tikzpicture}
    \caption{Vergleich der Ausführungsdauer ohne GCC Optimierung}
\end{figure}

Wie Grafik \ref{fig:executespeed} zeigt, wird das GCC Programm ohne Optimierung nur noch leicht schneller ausgeführt als die Programme der beiden anderen Compiler.
Da ebenfalls weder der THS- noch der QHScompiler über Optimierungsmethoden verfügen, ist dies das erwartete Resultat.
Aus zeitlichen Gründen war es mir nicht möglich Optimierung in meine beiden Compiler einzubauen.

Zusammengefasst lässt sich sagen, dass ohne Optimierung mein alternativer Aufbau eines Compilers ungefähr gleich schnelle Ausführungsgeschwindigkeit liefert, wie ein traditioneller Compiler.
Trotzdem muss man anmerken, dass Optimierung bei einem traditionellen Compiler möglich ist und die Ausführungsdauer deutlich verringert, wie GCC in Grafik \ref{fig:executespeed_optimized} beweist.
Ich kann mir vorstellen, dass Optimierung für einen nach meinem alternativen Aufbau entwickelten Compiler jedoch deutlich schwierig wäre.
Traditionelle Compiler haben die Möglichkeit Optimierungen auf dem AST auszuführen. Für meinem alternativen Compiler ist dies nicht möglich, da gar keine Syntax Analysis durchgeführt und nie ein AST generiert wird.
Auch steht die Grundidee meines alternativen Aufbaus Optimierung stark im Weg.
Wie zu Beginn von Abschnitt \ref{cha:4-QHS_Compiler} beschrieben, basiert mein Ansatz darauf, dass die von Macro Expansion verwendeten Macros während der Kompilerung erst definiert werden.
Daher kennt der QHScompiler vor der Kompilierung weder die Eingabe- noch die Ausgabesprache. Dies führt dazu, dass auch mögliche Optimierungsmethoden erst während dem Kompilieren gefunden werden können.
Aus diesen Gründen wäre Optimierung für einen Compiler nach meinem alternativen Aufbau deutlich komplexer, wenn nicht sogar unmöglich.


\section{Benutzerfreundlichkeit}
Benutzerfreundlichkeit ist im Gegensatz zu den beiden vorherigen Vergleichskriterien etwas Subjektives. Jedoch würde ich behaupten, dass auch hier das Urteil ziemlich klar ist.
GCC und der THScompiler folgen beide exakt definiertem Syntax und Semantik. Dies ist ein Resultat des Lexers und des Parsers die noch diesen bestimmten Regeln geschrieben wurden.
Anfangs scheinen Semikolons am Ende jedes Statements vielleicht etwas unnötig, jedoch bemerkt man schnell, dass genau diese Pingeligkeit der Compiler für eine Programmiersprache äusserst wichtig ist.
GCC fängt besonders gut Fehler früh ab und meldet diese. Der traditionelle Compiler ist somit sehr gut in puncto Benutzerfreundlichkeit.

Der QHScompiler weist bei der Benutzerfreundlichkeit hingegen einige Macken auf.
Wie im Abschnitt \ref{sec:qhs-funcs} bereits beschrieben, verfügt der QHScompiler über keine Möglichkeit zu überprüfen, ob eine bestimmte Order folgt oder nicht.
Er führt ganz einfach und strickt nur aus was als Nächstes auftaucht. Somit führt ein fehlendes Zeichen nicht immer zu Fehlern. Folgendes Beispiel kompiliert einwandfrei und lässt sich auch problemlos ausführen.

\begin{lstlisting}[language=QHS, caption=QHS mit fehlenden Tokens, label=eg:qhs-faulty-syntax-1]
int a = "69"    /* ; fehlt */
foo ( a  ;      /* ) fehlt */
\end{lstlisting}

Weder das Semikolon noch die schliessende Klammer bei \ref{eg:qhs-faulty-syntax-1} ist hierbei nötig und das Programm lässt sich problemlos kompilieren und ausführen. Jedoch kann dies auch anders laufen.

\begin{lstlisting}[language=QHS, caption=QHS mit fehlender (, label=eg:qhs-faulty-syntax-2]
int a = "69"    /* ; fehlt */
foo a ) ;       /* ( fehlt */
\end{lstlisting}

Der QHS Code bei \ref{eg:qhs-faulty-syntax-2} kompiliert einwandfrei, jedoch ist der generierte Assembly Code fehlerhaft. Die Funktion foo wird nicht ausgeführt und die Variable a nicht als Argument angesehen.

Weiter sind auch die Fehlermeldungen des QHScompilers nicht immer besonders klar.

\begin{lstlisting}[language=QHS, caption=QHS mit falscher Anzahl Argumente, label=eg:qhs-faulty-syntax-3]
void foo ( ) { }

start
{
    int a = "69" 
    foo ( a ) ;

    exit ;
}

%\noindent\hrulefill Output\noindent\hrulefill%
[ERROR] Cannot dequeue, OrderQueue is empty!
[ERROR] Expected LiteralCode for #literalToIdentifier at OrderQueue second, got: NONE
[ERROR] Cannot dequeue, OrderQueue is empty!
[ERROR] Tried #changeIntVar but second order (change) from OrderQueue is not direct code
[ERROR] Expected LiteralCode for #literalToIdentifier, got: NONE
[ERROR] Expected LiteralCode for #literalToIdentifier, got: NONE
[ERROR] Expected LiteralCode for #literalToIdentifier, got: NONE
\end{lstlisting}

Bei \ref{eg:qhs-faulty-syntax-3} wird die Funktion foo ohne Parameter definiert, später jedoch mit einem Argument aufgerufen. Der QHScompiler verfügt hierbei über keine Möglichkeit die Menge an Argumenten zu überprüfen
und meldet nicht direkt einen Fehler. Als er jedoch versucht die Grösse des erwarteten Argumentes von der OrderQueue zu nehmen ist diese leer.
Der QHScompiler meldet also einen OrderQueue-Empty Error gefolgt von vielen Folgefehlern.

%Ein weiterer Kritikpunkt am QHScompiler wäre die fehlende Semantic Analysis. Implizite Casts 

Somit ist der QHScompiler bei der Meldung von Fehlern einerseits weniger strikt, andererseits aber auch deutlich verwirrender und ungenauer als ein traditioneller Compiler.
In meinen Augen triumphiert daher auch in dieser Kategorie der traditionelle Compiler über meinen QHScompiler.

\section{Offenheit für Erweiterung}
Als eine auch professionell verwendete Programmiersprache, hat C selbstverständlich eine Vielzahl an Features. Zum Beispiel lassen sich mithilfe von Templates Datentyp unabhängige Datenstrukturen wie Stacks, Queues oder Vectors definieren.
Weiter lassen sich mit Libraries komplexe Algorithmen einmal schreiben und nachher ganz einfach wieder verwenden. All dies ist innerhalb eines traditionellen Compilers möglich.

Libraries lassen sich ebenfalls mit dem QHScompiler verwenden. Templates sollten theoretisch ebenfalls möglich sein, jedoch habe ich dies nicht getestet.
Jedoch unterstützt der QHScompiler, wie in Abschnitt \ref{cha:4-QHS_Compiler} bereits angetönt, noch weitere Möglichkeiten zur Erweiterung. 
Denn es ist möglich eigene Identifier zu definieren. Mit den im Abschnitt \ref{sec:qhs-funcs} beschriebenen Techniken DelayedExecute und TempAssign
lassen sich sogar selbstständig syntaktisch komplexe Code Strukturen bilden. Im Gegensatz zu einem traditionellen Compiler muss hierfür nicht einmal der QHScompiler angepasst werden.
Dadurch kann man unterschiedliche Programmiersprachen mit dem QHScompiler kompilieren. Es ist sogar möglich die Programmiersprache innerhalb einer Datei zu wechseln.
Leider ist die Definition der benötigten Macros für eine neue Programmiersprache nicht besonders intuitiv. 
Trotzdem würde ich sagen, dass der QHScompiler einem mehr Freiheit bei der Erweiterung bietet, als ein traditioneller Compiler.

\section{Fazit}
Im Vergleich mit traditionellen Compilern hat der QHScompiler nicht besonders gut abgeschnitten.
Er ist sowohl in der Geschwindigkeit der Kompilierung als auch bei der eines kompilierten Programmes einem traditionellen Compiler unterlegen.
Zudem ist der QHScompiler auch nicht besonders benutzerfreundlich und nicht wirklich angenehm zu verwenden. Als einziger Vorteil lässt sich seine Möglichkeit zur Erweiterung sehen.

Mithilfe eines Profilers habe ich die Kompilierungsdauer des QHScompilers analysiert. Daraus schloss ich, dass das System der Identifier besonders ineffizient ist. 
Jeder Identifier benötigt zuerst eine Abfrage bei den Environments. Diese Abfrage ist an sich keine aufwendige Sache, jedoch sind Identifiers häufig so verschachtelt, dass 

Aus dem Vergleich der Benutzerfreundlichkeit wird ausserdem klar, dass die Syntax Analysis für die angenehme Verwendung eines Compilers äusserst wichtig ist.
Durch den Parser lassen sich Fehler in der Eingabedatei früh finden und genau Melden. Dem QHScompiler ist dies folge der fehlenden Syntax Analysis nicht möglich.

Ausserdem ist ein AST, wie in Abschnitt \ref{sec:execute_speed} thematisiert, auch für die Optimierung der Ausgabedatei äusserst praktisch.
Grundsätzlich ist Optimierung für den QHScompiler äusserst schwierig. Da die Eingabesprache während der Kompilierung erst definiert wird, müssten auch passende Optimierungsmethoden spontan gefunden werden.
Dies äussert sich in einer langsameren Geschwindigkeit des Output-Codes.

Der einzige Vorteil des QHScompilers liegt in der Offenheit für Erweiterung.
Das Wechseln der Programmiersprache innerhalb einer Datei ist definitv interessant, jedoch habe ich noch kein Beispiel gefunden, wofür dieser Wechsel nötig wäre.
In den meisten Fällen könnte man auch die Teile mit unterschiedlichen Sprachen auf mehrere Dateien aufteilen, einzeln kompilieren und danach mit einem \textit{Linker} kombinieren.

Zusammengefasst führt das System der während der Kompilerung definierten Identifier zu hohen Kompierungsdauern, ungenauem Umgang mit Fehlern und mangelhafter Optimierung des Output-Codes.
Der QHScompiler ist einem traditionellen Compiler also stark unterlegen.
